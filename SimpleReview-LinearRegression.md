# 복습



### 선형 회귀 Linear Regression



__1) 단순 선형 회귀 분석 (Simple Linear Regression Analysis)__
$$
y = {Wx + b}
$$
W : 가중치(weight)

b : 편향(bias)



__2) 다중 선형 회귀 분석 (Multiple Linear Regression Analysis)__
$$
y = {W_1x_1 + W_2x_2 + ... W_nx_n + b}
$$
y is still one

Not one x, but several x


$$
H(x) = {Wx + b}
$$
__H__ means Hypothesis



##### What we have to do by LR is to find _appropriate W and b_



In ML, to find __W__ and __b__, we use __Cost function(Loss function)__   

Cost function is about the error between y and y^  

##### We have to minimize Cost function!

